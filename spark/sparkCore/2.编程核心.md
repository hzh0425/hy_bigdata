# spark核心编程

Spark 计算框架为了能够进行高并发和高吞吐的数据处理，封装了三大数据结构，用于处理不同的应用场景。三大数据结构分别是：

Ø RDD : 弹性分布式数据集

Ø 累加器：分布式共享只写变量

Ø 广播变量：分布式共享只读变量

接下来我们一起看看这三大数据结构是如何在数据处理中使用的。

## 一 RDD

### 1.什么是RDD

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200907210408911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNzI3MDk1,size_16,color_FFFFFF,t_70#pic_center)

RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的一种数据处理的模型。

代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。

RDD 是 Spark 提供的最重要的抽象概念，它是一种有容错机制的特殊数据集合，可以分布在集群的结点上，以函数式操作集合的方式进行各种并行操作。

本质上是一个只读的分区记录集合。每个 RDD 可以分成多个分区，每个分区就是一个数据集片段。一个 RDD 的不同分区可以保存到集群中的不同结点上，从而可以在集群中的不同结点上进行并行计算

- 弹性
  - 存储的弹性：计算过程中内存不够时，它会和磁盘进行数据交换（内存与磁盘的自动切换）
  - 容错的弹性：数据丢失可以自动恢复；
  - 计算的弹性：计算出错重试机制；
  - 分片的弹性：可以根据数据的变化，多次改变分区的数量，已最后一次提交的job分区为结果；
- 分布式（可分区）：每个 RDD 可以分成多个分区，每个分区就是一个数据集片段，一个 RDD 的不同分区可以保存到集群中的不同结点上，从而可以在集群中的不同结点上进行并行计算
- 数据集：RDD封装了计算逻辑，并不保存数据
- 数据抽象：RDD是一个抽象类，需要子类具体实现
- 不可变：RDD封装的是计算逻辑（不是数据），每个RDD一旦生成，是不可以改变的，若要对其修改逻辑，就会产生新的RDD

小结：一个 RDD 可以简单的理解为一个分布式的元素集合，

每个 RDD 可以分成多个分区，每个分区可以在集群中不同的节点上进行计算；

RDD 表示只读的数据集，对 RDD 进行改动，只能通过 RDD 的转换操作，得到新的 RDD，并不会对原本的 RDD 有任何影响；

在 Spark 中，所有的工作都是以操作 RDD 为主，要么是创建 RDD，要么是转换已经存在 RDD 成为新的 RDD，要么在 RDD 上去执行一些操作来得到一些计算结果；

### 2.核心属性

![在这里插入图片描述](https://gitee.com/zisuu/picture/raw/master/img/20210110223959.png)
![在这里插入图片描述](https://gitee.com/zisuu/picture/raw/master/img/20210110224003.png)

**分区列表**

RDD中的分区，即数据集的基本组成单位，每个分区可以运行在不同节点上；

对于RDD来说，每个分片都会被一个计算任务处理，并决定并行计算的粒度，是实现分布式计算的重要属性。
![在这里插入图片描述](https://gitee.com/zisuu/picture/raw/master/img/20210110224326.png)

**分区计算函数**

一个计算每个分区的函数。Spark中RDD的计算是以分片为单位的，相同的计算逻辑应用在不同分区中（即每个分区的计算逻辑是相同的）；

每个RDD都会实现compute函数以达到这个目的。compute函数会对迭代器进行复合，不需要保存每次计算的结果
![在这里插入图片描述](https://gitee.com/zisuu/picture/raw/master/img/20210110224330.png)

**RDD之间的依赖关系**

当需求中需要将多个计算模型进行组合时，就需要将多个RDD建立依赖关系；

RDD的每次转换都会生成一个新的RDD，所以RDD之间就会形成类似于流水线一样的前后依赖关系。

在部分分区数据丢失时，Spark可以通过这个依赖关系重新计算丢失的分区数据，而不是对RDD的所有分区进行重新计算。
![在这里插入图片描述](https://gitee.com/zisuu/picture/raw/master/img/20210110224340.png)

**分区器（可选）**

RDD的分区函数，即对数据的分区规则。主要有两种分区函数，一个是`基于哈希的HashPartitioner（默认）`，另外一个是`基于范围的RangePartitioner`。

只有key-value类型的RDD，才会有Partitioner，非key-value的RDD的Parititioner的值是None。

Partitioner函数不但决定了RDD本身的分区数量，也决定了parent RDD Shuffle输出时的分区数量。
![在这里插入图片描述](https://gitee.com/zisuu/picture/raw/master/img/20210110224334.png)

**首选位置（可选）**

计算数据的位置 （本地化级别），可以设置数据读取的偏好位置，用来将Task发送给指定的节点，就近原则（节省网络IO）

对于一个HDFS文件来说，这个列表保存的就是每个Partition所在的块的位置。

按照“移动数据不如移动计算”的理念，Spark在进行任务调度的时候，会尽可能地将计算任务分配到其所要处理数据块的存储位置。
![在这里插入图片描述](https://gitee.com/zisuu/picture/raw/master/img/20210110224336.png)

### 3.执行原理

 如图所示，在Spark应用中，整个执行流程在逻辑上运算之间会形成有向无环图。Action算子触发之后会将所有累积的算子形成一个有向无环图，然后由调度器调度该图上的任务进行运算。Spark的调度方式与MapReduce有所不同。Spark根据RDD之间不同的依赖关系切分形成不同的阶段（Stage），一个阶段包含一系列函数进行流水线执行。图中的A、B、C、D、E、F、G，分别代表不同的RDD，RDD内的一个方框代表一个数据块。数据从HDFS输入Spark，形成RDD A和RDD C，RDD C上执行map操作，转换为RDD D，RDD B和RDD F进行join操作转换为G，而在B到G的过程中又会进行Shuffle。最后RDD G通过函数saveAsSequenceFile输出保存到HDFS中。

![img](https://gitee.com/zisuu/picture/raw/master/img/20210110224827.jpeg)

从以上流程可以看出 RDD 在整个流程中主要用于将逻辑进行封装，并生成 Task 发送给Executor 节点执行计算，接下来我们就一起看看 Spark 框架中RDD 是具体是如何进行数据处理的。

### 4.基础编程



## 二 累加器





## 三 广播变量