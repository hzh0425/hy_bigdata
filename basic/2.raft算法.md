# 一、Raft算法概述

## 1、三种角色

  **Raft是一个用于管理日志一致性的协议**。它将分布式一致性分解为多个子问题：**Leader选举（Leader election）、日志复制（Log replication）、安全性（Safety）、日志压缩（Log compaction）等**。同时，Raft算法使用了更强的假设来减少了需要考虑的状态，使之变的易于理解和实现。**Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选者**（Candidate）：

- Leader：**接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志**。
- Follower：**接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志**。
- Candidate：**Leader选举过程中的临时角色**。
  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190722215348483.jpg)

  Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。Raft算法将时间分为一个个的**任期（term）**，每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。

## 2、Term

  **Raft 算法将时间划分成为任意不同长度的任期（term）**。任期用连续的数字进行表示。**每一个任期的开始都是一次选举（election），一个或多个候选人会试图成为领导人**。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。**Raft 算法保证在给定的一个任期最多只有一个领导人**。

## 3、RPC

  **Raft 算法中服务器节点之间通信使用远程过程调用（RPC）**，并且基本的一致性算法只需要两种类型的 RPC，为了在服务器之间传输快照增加了第三种 RPC。

【RPC有三种】：

- **RequestVote RPC**：**候选人在选举期间发起**。
- **AppendEntries RPC**：**领导人发起的一种心跳机制，复制日志也在该命令中完成**。
- **InstallSnapshot RPC**: 领导者使用该RPC来**发送快照给太落后的追随者**。

# 二、Leader选举

## 1、Leader选举的过程

 简单介绍

  首先需要了解Raft中的一个关键词:`Term`,本文中以下部分简单称为任期。任期通过连续的整数编号表示并且是单调递增的，代表任意长度的一段时间。在网络中所有服务器都有自己的任期编号，在网络中大部分正常运行阶段，所有服务器的任期号都是相同的。
Raft算法中服务器主要分为三种角色:`Leader`,`Follower`,`Candidate`，并且三种角色相互独立，也就是服务器在同一时间内只可能扮演其中一种角色。

- `Leader`:用于对所有用户的请求进行处理。以及之后要说明的日志的复制等等。
- `Follower`:不会主动发送消息，只响应来自`Leader`与`Candidate`的请求。
- `Candidate`:用于选举新的`Leader`。

  在本文介绍的范围内，网络状态分为两种情况:**选举阶段**，**正常运行阶段**。(网络状态还可能会有成员变化阶段，但不在本文范围内，所以暂时先不考虑).
并且每一个任期都是以选举阶段开始。但不一定以正常运行阶段结束。在某些情况下一个完整的任期可能全部为选举阶段。如下图:
![图](https://img2018.cnblogs.com/blog/1652302/202001/1652302-20200104145554351-712530469.png)

## 选举阶段->正常运行阶段

  在网络初始化时，网络中所有的服务器都以`Follower`的角色启动。由于`Follower`只被动接收消息。所以全网中所有服务器都处于等待状态。同时每一个服务器都在本地维护一个计时器。

- 计时器的作用很简单，就是判断当前阶段(选举阶段或正常运行阶段)是否超时。而当计时器超时后，任期将会

  所以在网络启动后所有服务器等待指定长度的一段时间过去以后。计时器将会超时。这时候计时器超时的服务器将转换自己的角色为`Candidate`。进入选举阶段。而进入选举阶段的`Candidate`将会做以下几件事:

1. 将自己的任期号加1.
2. 为自己投一票用以选举出新的`Leader`。
3. 将本地的计时器重置
4. 发送投票请求到网络中的其他所有的服务器。
5. 等待下一次的计时器超时

同时选举`Leader`具有以下几点要求:

1. 每个服务器在一个任期内只能投一票，并且使先到者先得(即投票给自己收到的第一个请求投票的，**满足要求**的服务器的请求)
2. 请求投票的消息中需要带有请求者所处的当前任期号。
3. 投票者只会投票给任期号大于等于自己当前任期号的服务器。
4. 关于日志的要求(下一篇文章再介绍)

在选举状态会出现三种结果:

1. 自己成功当选`Leader`
2. 网络中其他服务器当选`Leader`
3. 网络中没有服务器当选`Leader`

  当网络中某一个`Candidate`接收到网络中大多数成员的投票后，即可将自己的身份转换为`Leader`。在当选`Leader`后，该服务器将周期性地发送心跳信息(心跳信息包含成功当选`Leader`的服务器的当前任期号)到网络中其他服务器。在网络中其他的服务器收到心跳信息后检查心跳消息中的任期号是否大于等于自己的任期号。如果满足该条件的话`Candidate`将会转换为`Follower`状态，并重置计时器。而如果任期号小于自己的任期号，服务器将拒绝该心跳消息并继续处于`Candidate`状态。

  第三种情况为网络中没有服务器成功当选`Leader`。这种情况在当很多`Follower`同时成为`Candidate`时会发生。因为当角色转换为`Candidate`后将会将选票投给自己。从而导致选票被分散开来，没有`Candidate`可以得到网络中大部分节点的选票。从而没有节点可以成为`Leader`.这种情况下计时器将再次超时，网络状态将从选举阶段进入下一个选举阶段。同时`Candidate`将会再次执行上面说明的几件事。

  Raft算法采用了随机选举超时机制来避免出现这种情况。即当计时器超时后，服务器将随机延迟指定的时间后才进入选举阶段。
由于随机延迟的原因，将降低服务器在同一时间选举超时的情况，可以有效避免选票分散的情况。

## 正常运行阶段->选举阶段

  当`Leader`成功选举之后，将周期性发送心跳消息到网络中其他服务器。同时其他服务器将转换自己的角色为`Follower`。并且每次收到心跳消息后都会重置自己的计时器，防止超时再次进入选举阶段。

  而如果`Leader`因为特殊情况崩溃时，网络中的其他服务器将不再接收到心跳消息，在等待指定时间后计时器将会超时，从而再次进入选举阶段。

- 而如果`Leader`崩溃时间较短，可以在其他服务器计时器超时之间恢复，并发送心跳消息，网络仍然可以恢复为`Leader`崩溃之前的状态。
- 如果`Leader`崩溃时间较长，在网络中已有新的`Leader`选举产生后恢复，由于旧的`Leader`任期号将小于新的`Leader`，在旧的`Leader`接收到新的`Leader`发送的心跳消息后则会变为`Follower`状态。

## 总结

三种角色的转换情况:

![图](https://img2018.cnblogs.com/blog/1652302/202001/1652302-20200104145525858-271973058.png)

### `Candidate`

  服务器角色变为`Candidate`后:

1. 将自己的任期号加1.
2. 为自己投一票用以选举出新的`Leader`。
3. 将本地的计时器重置
4. 发送投票请求到网络中的其他所有的服务器。
5. 等待下一次的计时器超时

- 当接收到心跳消息(心跳消息中的任期号大于等于自己的任期号)后，变为`Follower`状态。
- 计时器超时，再次执行上面的5件事。
- 当自己接收到大多数选票后，变为`Leader`状态。

### `Follower`

  服务器角色变为`Follower`后:

- 等待

  ```
  Leader
  ```

  或者

  ```
  Candidate
  ```

  发送消息给自己。

  - 如果是心跳消息(心跳消息中的任期号大于等于自己的任期号)，则重置计时器。
  - 如果是选举消息(选举消息中的任期号大于自己的任期号)，则将自己变为`Candidate`，任期号更新为选举消息中的较大的任期号。重置计时器并返回投票响应信息。

- 或者网络处于正常运行状态时，如果收到客户端请求，将会将该请求重定向到`Leader`。

- 如果在指定时间间隔内没有收到心跳消息或者是选举消息，则角色变为`Candidate`。

### `Leader`

  服务器角色变为`Leader`后:

- 重置计时器，并周期性发送心跳消息(带有自己的任期号)到网络中其他服务器。
- 等待客户端请求消息。

# 三、日志复制（保证数据一致性）

先看以下日志所包含的基本内容:

1. 可以被复制状态机执行的命令
2. 任期号 :创建该日志时Leader所处的当前任期号
3. 索引号 :整数，用于标识日志所在的位置

日志的状态分为两种:未被提交，已被提交(日志为安全的，不会被删除或覆盖)。

### 1 正常情况

- 当

  ```
  Leader
  ```

  接收到由客户端发送的请求(请求中包含可以被复制状态机执行的命令)时，Leader将会把该请求作为新的内容添加到日志中(任期号为当前

  ```
  Leader
  ```

  所处的任期号，索引号为当前

  ```
  Leader
  ```

  本地存储的日志集合中的日志的最高索引号加1)。

  - `Leader`**在当前任期内最多只能创建一个给定索引号的日志(即不可能在一个任期内创建两个以上的具有相同索引的日志条目)**

- 然后将该日志通过`AppendEntries RPC`消息发送到网络中其他的服务器(以下简称`Follower`)，从而复制该日志。

- 在网络中`Follower`接收到该日志消息后则会返回复制成功的回复。

- 在`Leader`接收到网络中大部分的`Follower`的成功复制的回复之后，`Leader`便认为该日志**可以被提交**。此时`Leader`将会同时做三件事：

1. 将该日志应用到`Leader`本地的复制状态机
2. 向所有`Follower`发送消息通知所有接收到该日志的`Follower`将该日志进行提交，然后应用到各自本地的复制状态机
3. 将执行结果通知客户端

  当该日志消息成功在网络中大部分`Follower`本地的复制状态机执行过后，则可认为该日志**已被提交**。在当前日志被提交的过程中，如果`Leader`先前的某些日志还没有被提交，则将会一同提交。
  而网络中有些`Follower`可能由于网络状态原因反应缓慢或者崩溃，那么`Leader`将会无限次地尝试重复发送`AppendEntries RPC`消息到该`Follower`。直到成功为止。

#### 1.1 日志的一致性检查

  在上面，我们说了`Follower`在接收到`AppendEntries RPC`消息后则会返回复制成功的回复。实际上在接收到消息后会首先进行日志的一致性检查(正常情况下`Leader`与`Follower`的日志会保持一致，所以一致性检查不会失败),**一致性检查内容如下：**

- 在`Leader`创建`AppendEntries RPC`消息时，消息中将会包含当前日志之前日志条目的任期号与索引号。

- ```
  Follower
  ```

  在接受到

  ```
  AppendEntries RPC
  ```

  消息后，将会检查之前日志的任期号与索引号是否可以匹配到

  - 如果匹配到则说明和`Leader`之前的日志是保持一致的。
  - 如果没有匹配则会拒绝`AppendEntries RPC`消息.

  一致性检查是一个归纳的过程。**正常情况下**，网络中第一条日志一定满足日志的一致性检查，然后第二条日志中包含第一条日志的任期号与索引号，所以只要`Leader`与`Follower`的第一条日志保持一致，那么第二条日志也会满足一致性检查，从而之后的每一条日志都会满足一致性检查。

  从而得出了日志匹配属性:

- 如果两个不同的日志实体具有相同的索引和任期号，那么他们存储有相同的命令。
- 如果两个不同的日志实体具有相同的索引和任期号，则所有先前条目中的日志都相同。(由一致性检查结果得出)

### 2 特殊情况

  而网络不可能一直处于正常情况。因为`Leader`或者某个`Follower`有可能会崩溃，从而导致日志不能一直保持一致。因此存在以下三种情况:

1. `Follower`缺失当前`Leader`上存在的日志条目。
2. `Follower`存在当前`Leader`不存在的日志条目。(比如旧的`Leader`仅仅将`AppendEntries RPC`消息发送到一部分`Follower`就崩溃掉，然后新的当选`Leader`的服务器恰好是没有收到该`AppendEntries RPC`消息的服务器)
3. 或者`Follower`即缺失当前`Leader`上存在的日志条目，也存在当前`Leader`不存在的日志条目

![图](https://gitee.com/zisuu/picture/raw/master/img/20210214112248.png)

  图中最上方是日志的索引号(1-12),每个方块代表一条日志信息，方块内数字代表该日志所处的任期号。图中当前`Leader`(图中最上方一行日志代表当前`Leader`日志)处于任期号为8的时刻。以此图说明以上三种情况存在的原因：

- `Follower` *a,b*(`Follower`崩溃没有接收到`Leader`发送的`AppendEntries RPC`消息)满足以上说明的第一种情况。
- (`Follower`*c*在任期为6的时刻，`Follower`*d*在任期为7的时刻)为`Leader`,但没有完全完成日志的发送便崩溃了.满足以上说明的第三种情况。
- `Follower`*e*在任期为4的时刻,`Follower`*f*在任期为2,3的时刻为`Leader`,,但没有完全完成日志的发送便崩溃了,同时在其他服务器当选`Leader`时刻也没有接收到新的`Leader`发送的`AppendEntries RPC`消息,满足第三种情况。

#### 2.1 日志不一致的解决方案

  `Leader`通过强迫`Follower`的日志重复自己的日志来处理不一致之处。这意味着`Follower`日志中的冲突日志将被`Leader`日志中的条目覆盖。因此`Leader`必须找到与`Follower`最开始日志发生冲突的位置,然后删除掉`Follower`上所有与`Leader`发生冲突的日志。然后将自己的日志发送给`Follower`以解决冲突。
**`Leader`不会删除或覆盖自己本地的日志条目**

  这些步骤从之前说到的日志的一致性检查开始。

- 当发生日志冲突时，`Follower`将会拒绝由`Leader`发送的`AppendEntries RPC`消息，并返回一个响应消息告知`Leader`日志发生了冲突。
- `Leader`为每一个`Follower`维护一个`nextIndex`值。该值用于确定需要发送给该`Follower`的下一条日志的位置索引。(该值在当前服务器成功当选`Leader`后会重置为本地日志的最后一条索引号+1)
- 当`Leader`了解到日志发生冲突之后，便递减`nextIndex`值。并重新发送`AppendEntries RPC`到该`Follower`。并不断重复这个过程，一直到`Follower`接受该消息。
- 一旦`Follower`接受了`AppendEntries RPC`消息，`Leader`则根据`nextIndex`值可以确定发生冲突的位置，从而强迫`Follower`的日志重复自己的日志以解决冲突问题。

![图](https://gitee.com/zisuu/picture/raw/master/img/20210214112248.png)

- 情况*a*: 如图，服务器*S1*在任期为2的时刻仅将日志`<index:2,term:2>`发送到了服务器*S2*便崩溃掉。
- 情况*b*: 服务器*S5*在任期为3的时刻当选`Leader`(*S5*的计时器率先超时，递增任期号为3因此高于服务器*S3,S4*，可以当选`Leader`)，但没来得及发送日志便崩溃掉。
- 情况*c*: 服务器*S1*在任期为4的时刻再次当选`Leader`(*S1*重启时，任期仍然为2，收到新的`Leader`*S5*发送的心跳信息后更新任期为3，而在`Leader`*S5*崩溃后，服务器*S1*为第一个计时器超时的，因此发起投票，任期更新为4，大于网络中其他服务器任期，成功当选`Leader`),同时将日志`<index:2,term:2>`发送到了服务器*S2,S3*,但还没有通知服务器对日志进行提交便崩溃掉。
- 情况*d*: 情况(*a->d*)如果在任期为2时服务器*S1*作为`Leader`崩溃掉，*S5*在任期为3的时刻当选`Leader`，由于日志`<index:2,term:2>`还没有被复制到大部分服务器上，并没有被提交，所以*S5*可以通过自己的日志`<index:2,term:3>`覆盖掉日志`<index:2,term:2>`。
- 情况*e*: 情况(*a->e*)而如果在任期为2时服务器*S1*作为`Leader`，并将`<index:2,term:2>`发送到*S2,S3*,成功复制到大多数成员服务器上。并且成功提交了该日志，那么即便*S1*崩溃掉，*S5*也无法成功当选`Leader`，因为*S5*不具备网络中最新的已被提交的日志条目(**这里说明了上一篇文章[Raft算法之Leader选举](https://www.cnblogs.com/cbkj-xd/p/12150282.html)中选举`Leader`的要求中没有介绍的那一点要求**).

#### 2.2 选举`Leader`的对日志的要求

- Raft使用投票程序来防止`Candidate`赢得选举，除非其日志中包含所有已提交的日志条目。
- `Candidate`必须联系集群的大多数才能被选举，这意味着每个提交的条目都必须存在于其中至少一台服务器中。如果`Candidate`的日志至少与该多数服务器日志中的日志一样最新(以下精确定义了**最新**),则它将保存所有已提交的条目。
- Raft通过比较日志中最后一个条目的索引和任期来确定两个日志中哪个是最新的。如果日志中的最后一个条目具有不同的任期，则带有较新任期的日志是最新的。如果日志以相同的任期结尾，则以索引更大的日志为准。

  **解决方案的优化**
  在`Follower`拒绝`AppendEntries RPC`消息时，可以选择将发生冲突的日志的任期与该任期内的第一条日志索引包含在拒绝消息中返回给`Leader`，从而使得`Leader`可以快速定位到发生冲突的位置。有了这些信息，`Leader`可以递减`nextIndex`来绕过该任期中所有冲突的条目。每个具有**冲突日志条目所处的任期**都需要一个`AppendEntries RPC`消息，而不是每个日志条目都需要一个`AppendEntries RPC`消息。

### 3 日志复制安全性

**Raft保证任何时刻这里的每一条属性都成立**

- `Leader`只追加特性:`Leader`从不覆盖或删除它的日志条目，只追加新的。
- 日志匹配: 如果两个日志包含的实体具有相同的索引和任期，那么直到给定索引为止，所有条目中的日志都是相同的。
- `Leader`完整性:如果一个日志提示在给定的任期内被提交，那么该条目将出现在所有任期更高的领导者的日志中.
- 状态机安全:如果服务器应用一条给定索引的日志实体到它的状态机，那么没有其他服务器可以应用一条不同的日志到相同的索引位置。

#### 3.1 `Leader`完整性证明

  假设`Leader`完整性不成立，然后证明是矛盾的。
  假设任期为*T*的`Leader`提交了当前任期的日志条目，但是该日志没有被任期高于*T*的任期为*U*的未来的新的`Leader`所存储。

1. 被提交任期为*T*的日志必须不存在于将要选举的任期为*U*的`Leader`的复制状态机中(因为`Leader`从不覆盖或删除它的日志条目)。
2. 任期为*T*的`Leader`将日志复制到集群中的大部分成员本地。并且任期为*U*的`Leader`在选举阶段接收到集群中大部分成员的投票，因此至少集群中有一个成员(以下称为投票者)即接收到来自任期为*T*的`Leader`发送的日志，也为任期为*U*的`Leader`投了票。所以该投票者是证明矛盾的关键所在。
3. 投票者必须在为任期为*U*的`Leader`投票之前将任期为*T*的`Leader`的发送的日志提交。不然投票者将会拒绝任期为*T*的`Leader`的`AppendEntries PRC`请求(因为一旦接收到任期为*U*的`Leader`投票请求，投票者的任期将会高于*T*)。
4. 投票者当为任期为*U*的`Leader`投票时，将会一直存储该日志条目。假设在任期为*T*和*U*之间的每一个`Leader`都包含该日志条目(`Leader`从不删除日志条目，而`Follower`仅在与`Leader`冲突时才删除条目)。
5. 投票者为任期为*U*的`Leader`投票，所以任期为*U*的`Leader`日志必须至少和投票者的日志一样新。这将导致产生两个矛盾之中的一个矛盾。
6. 首先，如果投票者和任期为*U*的`Leader`具有相同的最新的日志任期。那么任期为*U*的`Leader`的日志至少和投票者的日志一样长。所以任期为*U*的`Leader`的日志将包含投票者所有的日志。这是一个矛盾，因为之前假设的投票者包含被提交的任期为*T*的日志，而任期为*U*的`Leader`不包含。
7. 否则，任期为*U*的`Leader`的最后一条日志的任期号必须大于投票者的最后一条日志的任期号。而且，它比*T*大，因为投票者的上一个日志任期号至少为*T*(它包含任期*T*中的所有已提交的条目)。创建任期为*U*的`Leader`的最后一个日志条目的较早的`Leader`必须在其日志中(通过假设)包含已提交的条目。然后，通过日志匹配属性，任期为*U*的`Leader`的日志还必须包含已提交的条目，这是矛盾的。
8. 这样就证明了矛盾，因此所有任期大于*T*的`Leader`都必须包含所有任期为*T*的被提交的日志。
9. 日志匹配属性保证未来的`Leader`还将包含间接提交的日志条目。

# 四、安全性

本部分着重于对算法正确性的说明, 对前面的 Leader Election 和 Log Replication 增加一些限制, 以保证算法正确性.

首先是对 Leader Election 的限制. 只有当 candidate 的日志是否不落后于自身的日志时, 节点才会同意 candidate 成为 leader. 这保证了 Leader Completeness 性质, 下面做详细阐述. 在某个 term 中, 当一条日志被 commit, 就说明该日志被复制到了大多数节点. 在其后的 term 中, candidate 要想成为 leader, 必须先获得大多数节点的同意. 也就要求 candidate 的日志不能落后于大多数节点, 即必须拥有大多数节点都有的日志. 而在前面的 term 中被 commit 的日志显然存在于大多数节点. 反之, 如果 candidate 不含前面的 term 中被 commit 的日志, 就不能得到大多数节点的同意, 也就不能成为 leader.

其次是对 commit log 的限制. 首先考虑论文中提到的一种情况, 如 Figure 1 所示(来源于大论文 Figure 7.3, 详细介绍参考论文中的说明). 这个例子的目的是为了说明对于旧的 term 中的日志, leader 不能根据日志是否已经复制到大多数节点来判断是否可以将此日志 commit. leader 只能按照前面所说的机制, 直接 commit 当前 term 的日志, 在 commit 当前 term 的日志时, 会先 commit 此日志前的未 commit 的日志. 这样就可以保证在之前的 term 中的日志得以被 commit. 图中最重要的部分在于说明了某个 term 中的一条日志可以先在一个 term 中被复制到小部分节点, 在后面的 term 继续复制到其他节点. 这是问题的核心原因.

![img](https://gitee.com/zisuu/picture/raw/master/img/20210214111649.jpeg)

# 五、日志压缩

最后的一部分是关于服务器日志压缩的，因为随着运行时间的增增长，日志信息也会变得越来越多，占有更多的空间。因此Raft采取了日志压缩的方法解决该问题，即将当前整个系统状态写入稳定存储的快照，然后该时间点之前的日志就可以丢弃掉，从而释放存储空间。

## 1 快照结构

![图](https://gitee.com/zisuu/picture/raw/master/img/20210214113020.png)

从图中可见，快照包括以下几个部分内容:

- lastIncludedIndex: 表明快照中最后一条日志的索引值。也就是说日志一直压缩到该索引值的位置。该值以前连续若干个索引值的日志被压缩为快照，而该值以后的日志则不在快照中。
- lastIncludedTerm:表明快照中最后一条日志所在的任期值。
- state machine state:复制状态机的当前状态。

集群中每一个服务器都可以独立地进行拍摄快照(只对已提交的日志进行快照的拍摄)，其中`lastIncludedIndex`与`lastIncludedTerm`值的存在时为了通过之前讲到的在日志复制中需要做的一致性检查。当服务器完成了该快照的写入之后，就可以将从快照中最后一条日志一直到先前所有的日志删除。

## 2 快照的发送

正常情况下，`Leader`的日志将会与`Follower`保持一致，但并不是所有情况都处于正常情况下，有时候可能因为`Follower`的反应缓慢或崩溃造成与`Leader`的日志不一致。所以有时候需要`Leader`将快照信息发送给`Follower`。快照信息是通过一个称为`InstallSnapshot`的RPC消息发送的，该消息的结构如下:

| **InstallSnapshot RPC** | **由Leader调用并按顺序发送打包的快照到Follower。**           |
| ----------------------- | ------------------------------------------------------------ |
| **参数：**              |                                                              |
| term                    | Leader的任期                                                 |
| leaderId                | 用以Follower可以重定向客户端的请求到Leader                   |
| lastIncludedIndex       | 快照将替换直到该索引的所有日志条目                           |
| lastIncludedTerm        | 快照中最后一条日志所在的任期值                               |
| offset                  | 快照文件的偏移量,简单来说就是该快照代表多少数量的连续个日志实体 |
| data[]                  | 从offset开始，快照内的数据数组                               |
| done                    | 如果这是最后一个快照则为true，说明该快照之后的日志暂时不需要拍摄快照 |

快照的发送会出现以下几种情况:

1. `Follower`的日志信息不包括快照中的日志信息，即缺少日志。
2. `Follower`的日志信息与快照中的日志信息发生冲突。
3. `Follower`的日志信息要多于快照中的日志信息。

至于前两种情况，`Follower`采取直接使用快照内容替代掉自己的日志。

- `Follower`只含有部分快照中的日志信息，那么直接删掉然后使用快照取代。
- `Follower`具有更多的日志信息的情况下，即`Follower`含有大于接收到的快照中的最后一条日志信息的索引的日志信息。那么直接使用快照代替快照中所包含的日志信息，至于快照之后的日志信息仍然保留。

### 2.1 疑问

为什么不像日志一样仅由`Leader`拍摄快照然后发送给`Follower`，而是允许每一个服务器独立生成快照信息呢？
很简单的答案，为了减少带宽使用，以及资源的浪费。因为正常情况下`Follower`具有生成快照的所有信息，在自己本地直接生成快照所需要消耗的资源要远远小于通过网络发送所需要的资源。另外也是降低`Leader`设计的复杂。因为如果仅由`Leader`生成快照的话，`Leader`则需要在向`Follower`发送日志的同时，还要兼顾快照的发送。

### 2.2 存在的问题

- 还有另外两个问题会影响每个快照。首先，服务器必须决定何时进行快照。如果服务器过于频繁地进行快照，则会浪费磁盘带宽和能量。如果快照太不频繁，则有耗尽其存储容量的风险，并且会增加重新启动期间加载日志所需的时间。一种简单的策略是在日志达到固定大小（以字节为单位）时拍摄快照。如果此大小设置为明显大于快照的预期大小，则用于快照的磁盘带宽开销将很小。
- 第二个问题是写快照可能要花费大量时间，拍摄快照会延迟正常操作。解决方案是使用写时复制技术，以便可以接受新的更新而不会影响快照的写入。例如，使用功能性数据结构构建的状态机自然支持这一点。或者，可以使用操作系统的写时复制支持（例如，Linux上的fork）来创建整个状态机的内存快照。

# 六、成员变更



  有时候可能会遇到需要对集群中的成员数量进行更新的操作，比较简单的做法将更新操作分为两个阶段进行，在第一个阶段将全部的使用旧的配置文件的集群*C_old*成员全部关闭，所以将不能对客户端的请求进行处理。然后在第二个阶段使用新的配置文件启动集群成员。一个很明显的劣势在于更新成员数量的时候有一段时间是无法对客户端请求进行处理的。
  Raft使用了一种新的方案对成员进行更新。在两阶段更新之间加入了一个配置转换阶段，称为联合共识。引入联合共识阶段，集群在进行成员关系变化的同时，不需要关闭集群成员，从而可以在更新成员数量的过程中也可以对客户端的请求进行处理。
  在联合共识阶段具有以下几点属性:

- 日志条目均复制到使用两种配置的所有服务器。
- 来自任一配置的任何服务器都可以充当领导者.
- 选举和日志的提交需要分别来自新旧配置的大多数人接受。

  联合共识允许集群中的单个服务器在不同的时间从旧的配置转换为新的配置，从而不会影响安全性。并且在整个配置更新期间可以继续为客户端提供服务。

## 1 配置更新过程

### 1.1 理想情况

  以向集群中添加新的成员为例，正常情况下假设该过程不涉及客户端发送的其他的新的请求:
  假设旧的配置文件称为*C_o*,新的配置文件称为*C_n*,旧的集群称为*C_old*,新添加的成员称为*C_new*.

- 当集群

  C_old

  在正常运行过程中(当前使用旧的配置文件

  C_o

  )，接收到来自客户端关于添加新成员的请求。

  - `Leader`接收到则直接处理，`Follower`接收到则会重定向到`Leader`.

- ```
  Leader
  ```

  创建一个用于更新配置的新的日志文件

  C_o_n

  (该日志配置文件表示

  C_old

  与

  C_new

  成员共存)，该配置文件按照正常流程复制到集群中大多数服务器(包括

  C_old,C_new

  )

  - 包括新成员*C_new*，**服务器始终使用其日志中的最新配置，而不管该条目是否被提交**，`Leader`将使用*C_o_n*规则来确定何时提交*C_o_n*的日志条目。
  - 也就是说本地只持有*C_o*配置日志文件的成员仍然使用旧的配置文件。当接收到*C_o_n*配置文件之后不论是否已经应用到复制状态机，都会使用*C_o_n*配置文件作为服务器的配置文件。

- 当新的日志文件*C_o_n*成功在集群中提交之后，进入了联合共识阶段。

- 进入联合共识阶段之后，`Leader`创建一个新的用于配置更新的新的配置文件*C_n*,并将该日志发送到大部分*C_new*服务器(文献中是这么说的，至此还没搞明白为什么不是所有的服务器)。

![img](https://img2018.cnblogs.com/blog/1652302/202001/1652302-20200106205440180-162103077.png)

- 当配置日志文件*C_n*成功提交之后，则表明成员更新过程结束，集群使用新的配置文件*C_n*按照正常的流程继续运行。

  如果不考虑客户端发送的新的请求以及服务器崩溃的情况下，可以把配置更新看做一个普通的日志文件，按照正常流程发送，提交，应用后便成功完成配置的更新。唯一不同的是普通的日志文件需要提交过后才会应用到复制状态机，而配置文件日志则是当服务器接收到之后，不论是否已经提交，接收到的配置信息都会生效。

### 1.2 联合共识阶段

  联合共识阶段:指的是*C_o_n*配置日志文件成功提交到集群中的大多数服务器，且*C_n*配置日志文件还没有提交到集群中的大多数服务器之间的时间段。
  在该阶段，任何操作(选举或者是其他的日志请求)对于*C_old*和*C_new*的成员来说都不能单独做出决策。即需要*C_old*与*C_new*中的大部分服务器同时做出决策。(因为日志的提交条件是成功复制到大多数的服务器，所以当*C_o_n*日志文件被提交之后，有可能还存在部分的服务器没有接收到*C_o_n*日志文件,仍然处于*C_old*阶段,*C_new*的成员也是如此)

## 2 `Leader`崩溃情况

![img](https://img2018.cnblogs.com/blog/1652302/202001/1652302-20200106205645224-573840096.png)

  分别从以下几个时间点说一下`Leader`在各个阶段发生崩溃的措施:

1. *C_o_n*配置日志文件未提交之前.
2. *C_o_n*配置日志文件提交之后，且*C_n*配置日志文件未提交前之间(联合共识阶段)的时间段
3. *C_n*配置日志文件提交之后.

### 2.1 *C_o_n*配置日志文件未提交之前

  从集群初始正常运行状态一直到*C_o_n*配置日志文件被提交这段时间，如果`Leader`奔溃，那么当选`Leader`的成员可能是使用*C_o*的成员，也可能是接收到*C_o_n*配置日志文件的成员。因为*C_o_n*配置日志文件还未被提交，所以`C_old`的成员可以单独做出决策。而`C_new`的成员还不能单独做出决策。

### 2.2 联合共识阶段

   *C_o_n*配置日志文件提交之后，且*C_n*配置日志文件未提交前之间的时间段，由于*C_o_n*配置日志文件只有当复制到*C_old*和*C_new*两者中大多数成员之后才被提交，所以当提交*C_o_n*配置日志文件之后，使用*C_o_n*配置日志文件的成员占全部服务器成员的大多数，因此，如果`Leader`崩溃，那么只能从使用*C_o_n*配置日志文件的成员中选取`Leader`。此时对于*C_old*和*C_new*的成员来说都不能单独做出决策，因此也不能在使用*C_o*以及*C_n*的成员中选取`Leader`.

### 2.3 *C_n*配置日志文件提交之后

  当该日志提交之后，实际上已经完成了网络中成员关系的更新。所以`Leader`的选举即可和正常运行阶段相同。

## 3 存在的问题

  在成员关系更新阶段，主要存在三个问题:

1. 新添加的成员可能不会存储任何之前的日志条目，如果将它们加入集群，在日志条目与`Leader`完成同步之前，是无法提交新的日志条目的。
2. `Leader`可能不属于新配置集群中的一部分。
3. 假设更新成员关系是对集群中的成员进行删除，那么被删除的节点可能会扰乱集群。

### 3.1 问题一

  针对该问题，Raft的做法是引入一个新的状态，即允许新的成员以一种不具备决策权(选举和参与日志提交)的身份加入集群，因此在选举`Leader`或者是统计日志是否已经分发到大部分成员时，将不会考虑该成员。一直到该成员的日志存储状态追赶上集群中的其他成员，再赋予该成员决策权。

### 3.2 问题二

**原因**：  该问题产生的原因是可能新添加到集群中的新成员的数量要远远多于旧集群的数量(**个人理解，如果有错误欢迎指出**)。由于之前说到的*C_n*配置日志文件需要发送到*C_new*中的大多数成员，而`Leader`并不属于`C_new`中的一员。所以在发送*C_n*配置日志文件的时段，`Leader`将会对*C_new*的成员进行管理。
**解决方案**:  当*C_n*日志成功完成提交时，该`Leader`自动转换身份为`Follower`，然后从*C_new*的成员中选举出一个新的`Leader`.

### 3.3 问题三

**原因**:  被删除的服务器如果没有关闭，那么他们将不会接收到心跳信息和日志信息，从而不断发生超时，最后导致任期不断增加(高于集群中所有成员的任期)，然后不断向集群中发送请求投票消息。集群中的`Leader`将变为`Follower`，集群中将不断开始新的选举。从而扰乱集群的正常运行。
**解决方案**:   Raft引入了一个最小选举超时时间，意思是如果集群中存在`Leader`时，并且接收到心跳信息之后在最小选举超时时间内接受到请求投票消息，那么将会忽略掉该投票消息。

# 七、关于Raft的一些面试题

## 1、Raft分为哪几个部分？

  **主要是分为leader选举、日志复制、日志压缩、成员变更等**。

## 2、Raft中任何节点都可以发起选举吗？

  Raft发起选举的情况有如下几种：

- 刚启动时，所有节点都是follower，这个时候发起选举，选出一个leader；
- 当leader挂掉后，**时钟最先跑完的follower发起重新选举操作**，选出一个新的leader。
- 成员变更的时候会发起选举操作。

## 3、Raft中选举中给候选人投票的前提？

  **Raft确保新当选的Leader包含所有已提交（集群中大多数成员中已提交）的日志条目**。这个保证是在RequestVoteRPC阶段做的，candidate在发送RequestVoteRPC时，会带上自己的**last log entry的term_id和index**，follower在接收到RequestVoteRPC消息时，**如果发现自己的日志比RPC中的更新，就拒绝投票**。日志比较的原则是，如果本地的最后一条log entry的term id更大，则更新，如果term id一样大，则日志更多的更大(index更大)。

## 4、Raft网络分区下的数据一致性怎么解决？

  发生了网络分区或者网络通信故障，**使得Leader不能访问大多数Follwer了，那么Leader只能正常更新它能访问的那些Follower，而大多数的Follower因为没有了Leader，他们重新选出一个Leader**，然后这个 Leader来接受客户端的请求，如果客户端要求其添加新的日志，这个新的Leader会通知大多数Follower。**如果这时网络故障修复 了，那么原先的Leader就变成Follower，在失联阶段这个老Leader的任何更新都不能算commit，都回滚，接受新的Leader的新的更新（递减查询匹配日志）**。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190810162203146.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhYWlrdWFpY2h1YW4=,size_16,color_FFFFFF,t_70)

## 5、Raft数据一致性如何实现？

  **主要是通过日志复制实现数据一致性，leader将请求指令作为一条新的日志条目添加到日志中，然后发起RPC 给所有的follower，进行日志复制，进而同步数据**。

## 6、Raft的日志有什么特点？

  **日志由有序编号（log index）的日志条目组成，每个日志条目包含它被创建时的任期号（term）和用于状态机执行的命令**。

## 7、Raft和Paxos的区别和优缺点？

- Raft的leader有限制，**拥有最新日志的节点才能成为leader**，multi-paxos中对成为Leader的限制比较低，**任何节点都可以成为leader**。
- **Raft中Leader在每一个任期都有Term**号。

## 8、Raft prevote机制？

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190811094829159.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhYWlrdWFpY2h1YW4=,size_16,color_FFFFFF,t_70)
  **Prevote（预投票）是一个类似于两阶段提交的协议**，**第一阶段先征求其他节点是否同意选举，如果同意选举则发起真正的选举操作，否则降为Follower角色**。这样就**避免了网络分区节点重新加入集群，触发不必要的选举操作**。

## 9、Raft里面怎么保证数据被commit，leader宕机了会怎样，之前的没提交的数据会怎样？

  **leader会通过RPC向follower发出日志复制，等待所有的follower复制完成，这个过程是阻塞的**。

  **老的leader里面没提交的数据会回滚，然后同步新leader的数据**。

## 10、Raft日志压缩是怎么实现的？增加或删除节点呢？？

  在实际的系统中，**不能让日志无限增长**，否则**系统重启时需要花很长的时间进行回放**，从而影响可用性。**Raft采用对整个系统进行snapshot来解决，snapshot之前的日志都可以丢弃（以前的数据已经落盘了）**。

  **snapshot里面主要记录的是日志元数据，即最后一条已提交的 log entry的 log index和term**。

## 11、Raft里面的lease机制是什么，有什么作用？

  **租约机制确保了一个时刻最多只有一个leader，避免只使用心跳机制产生双主的问题**。**中心思想是每次租约时长内只有一个节点获得租约、到期后必须重新颁发租约**。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190811102518447.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhYWlrdWFpY2h1YW4=,size_16,color_FFFFFF,t_70)

## 12、Raft协议的leader选举，正常情况下，网络抖动造成follower发起leader选举，且该follower的Term比现有leader高，集群中所有结点的日志信息当前一致，这种情况下会选举成功吗？

  **参考网络分区的情况**。