## 一 时间语义

![image-20210122221917283](https://gitee.com/zisuu/picture/raw/master/img/20210122221946.png)

• Event Time：事件创建的时间

• Ingestion Time：数据进入Flink的时间

• Processing Time：执行操作算子的本地系统时间，与机器相关

• 不同的时间语义有不同的应用场合

• 我们往往更关心事件时间（Event Time）

• Event Time 可以从日志数据的时间戳（timestamp）中提取

➢ 2017-11-02 18:37:15.624 INFO Fail over to rm

我们可以直接在代码中，对执行环境调用 setStreamTimeCharacteristic 

方法，设置流的时间特性

• 具体的时间，还需要从数据中提取时间戳（timestamp）

![image-20210122222023732](https://gitee.com/zisuu/picture/raw/master/img/20210122222023.png)

## 二waterMark

### 1.乱序的影响

![image-20210122222049549](https://gitee.com/zisuu/picture/raw/master/img/20210122222049.png)

• 当 Flink 以 Event Time 模式处理数据流时，它会根据数据里的时间戳来

处理基于时间的算子

• 由于网络、分布式等原因，会导致乱序数据的产生

• 乱序数据会让窗口计算不准确

### 2.乱序的解决

![image-20210122222632545](https://gitee.com/zisuu/picture/raw/master/img/20210122222632.png)

对于（1,4,5),如何等待3和2的来临？

唯一的办法就是再等一会，比如等个1秒，再关闭这个（1-5）的窗口，使尽量多的数据能落在这个窗口内

那么watermark就是基于这个思想

### 3.watermark的定义



• watermark 是一条特殊的数据记录

• watermark 必须单调递增，以确保任务的事件时间时钟在向前推进，而

不是在后退

• watermark 与数据的时间戳相关

![](https://gitee.com/zisuu/picture/raw/master/img/20210122222918.png)

还是这幅图，比如我们设置了延迟等待2秒，窗口大小为5

来1  watermark=-1 此时-1<5,不关闭

来4 wm=4-2   2<5,不关闭

5 vm=3 ...

再来2，但是2<wm,所以2被丢弃

...

一直到来7 此时wm=5,窗口（1-5）关闭

这就是watermark,用来推进窗口的关闭，解决乱序问题的一大助手





## 三 watermark API

### 1.乱序

• Event Time 的使用一定要指定数据源中的时间戳

• 调用 assignTimestampAndWatermarks 方法，传入一个

BoundedOutOfOrdernessTimestampExtractor，就可以指定

![image-20210122225028821](https://gitee.com/zisuu/picture/raw/master/img/20210122225028.png)

其中time.second(1)就是指延迟时间

### 2.有序

• 对于排好序的数据，不需要延迟触发，可以只指定时间戳就行了

![image-20210122225227864](https://gitee.com/zisuu/picture/raw/master/img/20210122225227.png)



### 3.自定义

• Flink 暴露了 TimestampAssigner 接口供我们实现，使我们可以自定义

如何从事件数据中抽取时间戳和生成watermark

➢ *MyAssigner 可以有两种类型，都继承自 TimestampAssigner*

**TimestampAssigner**

• 定义了抽取时间戳，以及生成 watermark 的方法，有两种类型

➢ AssignerWithPeriodicWatermarks

周期性的生成 watermark：系统会周期性的将 watermark 插入到流中

默认周期是200毫秒，可以使用

ExecutionConfig.setAutoWatermarkInterval() 方法进行设置

```
// 每隔 5 秒产生一个 watermark
	
env.getConfig.setAutoWatermarkInterval(5000);
```

升序和前面乱序的处理 BoundedOutOfOrdernessTimestampExtractor，

都是基于周期性 watermark 的。 

➢ AssignerWithPunctuatedWatermarks

没有时间周期规律，可打断的生成 watermark



**例子，自定义一个周期性的时间戳抽取**

```
// 自定义周期性时间戳分配器
public static class MyPeriodicAssigner implements
AssignerWithPeriodicWatermarks<SensorReading>{


private Long bound = 60 * 1000L;	// 延迟一分钟
private Long maxTs = Long.MIN_VALUE;	// 当前最大时间戳

@Nullable @Override
public Watermark getCurrentWatermark() {
return new Watermark(maxTs - bound);
}


@Override
public long extractTimestamp(SensorReading element, long previousElementTimestamp)
{
maxTs = Math.max(maxTs, element.getTimestamp());
return element.getTimestamp();
}
}
```

**间断抽取（当id=sensor_1）**

```
public static class MyPunctuatedAssigner implements
AssignerWithPunctuatedWatermarks<SensorReading>{


private Long bound = 60 * 1000L;	// 延迟一分钟

@Nullable @Override
public Watermark checkAndGetNextWatermark(SensorReading lastElement, long
extractedTimestamp) {
if(lastElement.getId().equals("sensor_1"))
return new Watermark(extractedTimestamp - bound); else
return null;
}


@Override
public long extractTimestamp(SensorReading element, long previousElementTimestamp)
{
return element.getTimestamp();
}
}
```

## 四 window窗口与watermark的配合

代码：

```
   public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);
        // 从文件中读取数据
        DataStream<String> inputDataSet = env.socketTextStream("localhost",9000);
        DataStream<sensorRead> mapStream = inputDataSet.map(line -> {
            String[] fields = line.split(" ");
            return new sensorRead(fields[0], new Long(fields[1]),new Integer(fields[1]));
        });
        //定义事件事件戳
        DataStream<sensorRead> readSingleOutputStreamOperator = mapStream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor<sensorRead>(Time.seconds(2)) {
            @Override
            public long extractTimestamp(sensorRead sensorRead) {
                return sensorRead.getTime() * 1000L;
            }
        });
        //window需要先分流
        //聚合，窗口大小为15秒，根据温度聚合
        DataStream<sensorRead> result = readSingleOutputStreamOperator.keyBy("id").timeWindow(Time.seconds(15))
                .minBy("temperature");
        result.print();
        env.execute();
    }

	@Data
    public static class sensorRead{
        public String id;
        public Long time;

        public sensorRead(String id, Long time, int temperature) {
            this.id = id;
            this.time = time;
            this.temperature = temperature;
        }

        public int  temperature;



        @Override
        public String toString() {
            return "sensorRead{" +
                    "id='" + id + '\'' +
                    ", time=" + time +
                    ", temperature=" + temperature +
                    '}';
        }
    }
```

socket输入：

```
sensor_1 1547718199 35.8
sensor_2 1547718205 35.9
sensor_3 1547718206 35.7
```

此时无任何反应，watermark此时为206-2=204

但是当输入：

```
sensor_1 1547718212 35.6
```

就会输出：

```
sensorRead{id='sensor_1', time=1547718199, temperature=35.6}
sensorRead{id='sensor_2', time=1547718205, temperature=35.9}
sensorRead{id='sensor_3', time=1547718206, temperature=35.7}
```

因为此时watermark为210,第一条数据是199，也决定了窗口是(195-210)

所以当wm为210时，窗口便关闭



## 五 双重保证

当窗口关闭时，还想要保存或输出迟到的数据怎么办呢？

可以定义outputtag配合

```
        //定义事件事件戳
        DataStream<sensorRead> readSingleOutputStreamOperator = mapStream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor<sensorRead>(Time.seconds(2)) {
            @Override
            public long extractTimestamp(sensorRead sensorRead) {
                return sensorRead.getTime() * 1000L;
            }
        });
        OutputTag<sensorRead> outputTag = new OutputTag<sensorRead>("late"){};
        //window需要先分流
        //聚合，窗口大小为15秒，根据温度聚合,允许迟到一分钟
        SingleOutputStreamOperator<sensorRead> result = readSingleOutputStreamOperator
                .keyBy("id")
                .timeWindow(Time.seconds(15))
                .allowedLateness(Time.minutes(1))
                .sideOutputLateData(outputTag)
                .minBy("temperature");
        result.getSideOutput(outputTag).print();
        result.print("minTemp");
        env.execute();
```

比如，对于迟到数据，可以通过foreach保存到数据库等.....



## 五 并行任务下的watermark

### 4.watermark的传递



![image-20210122223552860](https://gitee.com/zisuu/picture/raw/master/img/20210122223552.png)

当前的watermark受上游的影响，取上游中最小的一个（木桶原理）

改变watermark，会及时传递到下游

若设置并行度为4：

```
   public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(4);
        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);
        // 从文件中读取数据
        DataStream<String> inputDataSet = env.socketTextStream("localhost",9000);
        DataStream<sensorRead> mapStream = inputDataSet.map(line -> {
            String[] fields = line.split(" ");
            return new sensorRead(fields[0], new Long(fields[1]),new Integer(fields[1]));
        });
        //定义事件事件戳
        DataStream<sensorRead> readSingleOutputStreamOperator = mapStream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor<sensorRead>(Time.seconds(2)) {
            @Override
            public long extractTimestamp(sensorRead sensorRead) {
                return sensorRead.getTime() * 1000L;
            }
        });
        //window需要先分流
        //聚合，窗口大小为15秒，根据温度聚合
        DataStream<sensorRead> result = readSingleOutputStreamOperator.keyBy("id").timeWindow(Time.seconds(15))
                .minBy("temperature");
        result.print();
        env.execute();
    }
```

此时就不会像上面的例子一样，在输入212时关闭195-210的窗口

因为map操作在此时算是上游，下游是开窗

![image-20210125163807236](https://gitee.com/zisuu/picture/raw/master/img/20210125163807.png)



每来一条数据，就会round到上游的某一个分区

并更新该分区的wm,并将该wm广播到下游的所有分区

因此，只有上游的wm都到了210，下游才会更新到210并关闭